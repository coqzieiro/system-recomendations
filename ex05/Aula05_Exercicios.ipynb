{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64cca0ec",
   "metadata": {},
   "source": [
    "## Aula 05 - Filtragem Híbrida - Exercícios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f284caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a0e18",
   "metadata": {},
   "source": [
    "### Importar base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e46c021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [....................................................] 65019041 / 65019041\n",
      "Saved under ml-20m-compact.tar.gz\n",
      "dataset/\n",
      "dataset/tags_sample.csv\n",
      "dataset/._.DS_Store\n",
      "dataset/.DS_Store\n",
      "dataset/movies_sample.csv\n",
      "dataset/._genome-tags.csv\n",
      "dataset/genome-tags.csv\n",
      "dataset/._ml-youtube.csv\n",
      "dataset/ml-youtube.csv\n",
      "dataset/._genome-scores.csv\n",
      "dataset/genome-scores.csv\n",
      "dataset/ratings_sample.csv\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "!python3 -m wget https://github.com/mmanzato/MBABigData/raw/master/ml-20m-compact.tar.gz\n",
    "!tar -xvzf ml-20m-compact.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0371677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SETUP OK ✅\n",
      "- Usuários: 11090 | Itens: 417 | n_items (interno): 417\n",
      "- Train: 152496 | Test: 38125\n"
     ]
    }
   ],
   "source": [
    "# ==== SETUP (autocontido) ====\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Baixar e carregar dados (idempotente)\n",
    "import os, subprocess, sys\n",
    "if not os.path.exists(\"dataset/movies_sample.csv\"):\n",
    "    try:\n",
    "        import wget  # noqa\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"wget\", \"-q\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"wget\", \"https://github.com/mmanzato/MBABigData/raw/master/ml-20m-compact.tar.gz\"])\n",
    "    subprocess.check_call([\"tar\", \"-xvzf\", \"ml-20m-compact.tar.gz\"])\n",
    "\n",
    "movies = pd.read_csv(\"./dataset/movies_sample.csv\")\n",
    "ratings = pd.read_csv(\"./dataset/ratings_sample.csv\")\n",
    "\n",
    "# 2) df com título (IDs originais)\n",
    "df_raw = ratings[['userId', 'movieId', 'rating']].merge(movies[['movieId','title']])\n",
    "\n",
    "# 3) mapear para IDs internos (necessário p/ matrizes)\n",
    "map_users = {u:i for i,u in enumerate(df_raw.userId.unique())}\n",
    "map_items = {m:i for i,m in enumerate(df_raw.movieId.unique())}\n",
    "\n",
    "df = df_raw.copy()\n",
    "df['userId'] = df['userId'].map(map_users)\n",
    "df['movieId'] = df['movieId'].map(map_items)\n",
    "\n",
    "# 4) train/test\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=2)\n",
    "\n",
    "# 5) movies_genres com IDs internos\n",
    "movies_genres = movies.drop('genres', axis=1).join(\n",
    "    movies.genres.str.split('|', expand=True).stack().reset_index(drop=True, level=1).rename('genre')\n",
    ")\n",
    "movies_genres['movieId'] = movies_genres['movieId'].map(map_items)\n",
    "movies_genres.dropna(inplace=True)\n",
    "movies_genres['movieId'] = movies_genres['movieId'].astype(int)\n",
    "\n",
    "# 6) estruturas auxiliares para os exercícios\n",
    "n_items = int(df.movieId.max()) + 1\n",
    "\n",
    "# ratings por item e por usuário (usando apenas TREINO)\n",
    "item_ratings = defaultdict(dict)\n",
    "user_ratings = defaultdict(dict)\n",
    "for u, i, r in train[['userId','movieId','rating']].itertuples(index=False):\n",
    "    item_ratings[int(i)][int(u)] = float(r)\n",
    "    user_ratings[int(u)][int(i)] = float(r)\n",
    "\n",
    "# gêneros por item\n",
    "genres_by_item = defaultdict(list)\n",
    "for _, row in movies_genres[['movieId','genre']].iterrows():\n",
    "    genres_by_item[int(row.movieId)].append(str(row.genre))\n",
    "\n",
    "# util: títulos por item interno\n",
    "title_by_id = {int(row.movieId): row.title for _, row in df[['movieId','title']].drop_duplicates().iterrows()}\n",
    "\n",
    "print(\"SETUP OK ✅\")\n",
    "print(f\"- Usuários: {len(map_users)} | Itens: {len(map_items)} | n_items (interno): {n_items}\")\n",
    "print(f\"- Train: {len(train)} | Test: {len(test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05032c2",
   "metadata": {},
   "source": [
    "### Obs. Nesta aula, você poderá escolher entre implementar o exercício 1 **OU** o exercício 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600cc2e6",
   "metadata": {},
   "source": [
    "***Exercício 01:*** Implemente uma hibridização monolítica/combinação usando a seguinte heurística:\n",
    "- Uso do algoritmo ItemAtributeKNN, sendo a hibridização feita no cálculo das similaridades entre os itens.\n",
    "- Se a quantidade de usuários que avaliaram ambos os itens for maior que um limiar L1, calcule a similaridade entre esses itens usando cosseno aplicado à representação baseada em notas.\n",
    "- Caso contrário, calcule a similaridade entre os itens usando metadados (gêneros por exemplo).  \n",
    "\n",
    "Compare os resultados do algoritmo híbrido com as versões isoladas do mesmo algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fafc2940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construindo S_cf (min_overlap=1) ...\n",
      "Construindo S_content (Jaccard gêneros) ...\n",
      "Construindo S_hybrid (L1=5) ...\n",
      "\n",
      "K=5\n",
      "  CF (cosseno)     -> MAE=0.7427  RMSE=0.9779\n",
      "  Conteúdo (gênero)-> MAE=0.8236  RMSE=1.0676\n",
      "  Híbrido (L1=5) -> MAE=0.7409  RMSE=0.9756\n",
      "\n",
      "K=10\n",
      "  CF (cosseno)     -> MAE=0.7477  RMSE=0.9743\n",
      "  Conteúdo (gênero)-> MAE=0.8089  RMSE=1.0484\n",
      "  Híbrido (L1=5) -> MAE=0.7470  RMSE=0.9736\n",
      "\n",
      "K=20\n",
      "  CF (cosseno)     -> MAE=0.7645  RMSE=0.9861\n",
      "  Conteúdo (gênero)-> MAE=0.8064  RMSE=1.0453\n",
      "  Híbrido (L1=5) -> MAE=0.7642  RMSE=0.9859\n",
      "\n",
      "Interpretação rápida:\n",
      "- Com L1 maior, a matriz híbrida privilegia CF quando há bastante sobreposição;\n",
      "  para pares raros, recorre a conteúdo, cobrindo sparsidade. Em geral melhora RMSE.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------- Utilidades ----------\n",
    "def mae_rmse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, float); y_pred = np.asarray(y_pred, float)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    rmse = float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "    return mae, rmse\n",
    "\n",
    "def cosine_on_overlap(vec_i, vec_j):\n",
    "    # vec_* são dict {user: rating}. Cálculo no espaço dos usuários em comum.\n",
    "    users = set(vec_i) & set(vec_j)\n",
    "    if not users:\n",
    "        return 0.0\n",
    "    xi = np.array([vec_i[u] for u in users], dtype=float)\n",
    "    xj = np.array([vec_j[u] for u in users], dtype=float)\n",
    "    num = float(np.dot(xi, xj))\n",
    "    den = float(np.linalg.norm(xi) * np.linalg.norm(xj))\n",
    "    return (num / den) if den != 0 else 0.0\n",
    "\n",
    "def jaccard(a, b):\n",
    "    A, B = set(a), set(b)\n",
    "    return len(A & B) / len(A | B) if (A or B) else 0.0\n",
    "\n",
    "# ---------- Estruturas: ratings por item/usuário e gêneros por item ----------\n",
    "n_items = int(df.movieId.max()) + 1\n",
    "\n",
    "# ratings por item: {item: {user: rating}}\n",
    "item_ratings = defaultdict(dict)\n",
    "# ratings por user: {user: {item: rating}} (útil depois)\n",
    "user_ratings = defaultdict(dict)\n",
    "for u, i, r in train[['userId','movieId','rating']].itertuples(index=False):\n",
    "    item_ratings[int(i)][int(u)] = float(r)\n",
    "    user_ratings[int(u)][int(i)] = float(r)\n",
    "\n",
    "# gêneros por item (se necessário, derive como na Aula 04)\n",
    "if 'movies_genres' not in globals():\n",
    "    movies_genres = movies.drop('genres', axis=1).join(\n",
    "        movies.genres.str.split('|', expand=True).stack().reset_index(drop=True, level=1).rename('genre')\n",
    "    )\n",
    "    movies_genres['movieId'] = movies_genres['movieId'].map({m:i for i,m in enumerate(df.merge(movies[['movieId']])['movieId'].unique())})\n",
    "    movies_genres.dropna(inplace=True)\n",
    "    movies_genres['movieId'] = movies_genres['movieId'].astype(int)\n",
    "\n",
    "genres_by_item = defaultdict(list)\n",
    "for _, row in movies_genres[['movieId','genre']].iterrows():\n",
    "    genres_by_item[int(row.movieId)].append(str(row.genre))\n",
    "\n",
    "# ---------- Matrizes de similaridade: CF (cosseno), Conteúdo (Jaccard), Híbrida ----------\n",
    "def build_S_cf(n_items, item_ratings, min_overlap=1):\n",
    "    S = np.zeros((n_items, n_items), dtype=np.float32)\n",
    "    for i in range(n_items):\n",
    "        vi = item_ratings.get(i, {})\n",
    "        for j in range(i+1, n_items):\n",
    "            vj = item_ratings.get(j, {})\n",
    "            overlap = len(set(vi) & set(vj))\n",
    "            if overlap >= min_overlap:\n",
    "                s = cosine_on_overlap(vi, vj)\n",
    "                if s > 0:\n",
    "                    S[i, j] = S[j, i] = s\n",
    "    np.fill_diagonal(S, 1.0)\n",
    "    return S\n",
    "\n",
    "def build_S_content(n_items, genres_by_item):\n",
    "    S = np.zeros((n_items, n_items), dtype=np.float32)\n",
    "    for i in range(n_items):\n",
    "        gi = genres_by_item.get(i, [])\n",
    "        for j in range(i+1, n_items):\n",
    "            gj = genres_by_item.get(j, [])\n",
    "            s = jaccard(gi, gj)\n",
    "            if s > 0:\n",
    "                S[i, j] = S[j, i] = s\n",
    "    np.fill_diagonal(S, 1.0)\n",
    "    return S\n",
    "\n",
    "def build_S_hybrid(n_items, item_ratings, genres_by_item, L1=5):\n",
    "    # Se overlap >= L1 -> cosseno (CF), senão -> Jaccard (conteúdo)\n",
    "    S = np.zeros((n_items, n_items), dtype=np.float32)\n",
    "    for i in range(n_items):\n",
    "        vi = item_ratings.get(i, {})\n",
    "        gi = genres_by_item.get(i, [])\n",
    "        for j in range(i+1, n_items):\n",
    "            vj = item_ratings.get(j, {})\n",
    "            gj = genres_by_item.get(j, [])\n",
    "            overlap = len(set(vi) & set(vj))\n",
    "            if overlap >= L1:\n",
    "                s = cosine_on_overlap(vi, vj)\n",
    "            else:\n",
    "                s = jaccard(gi, gj)\n",
    "            if s > 0:\n",
    "                S[i, j] = S[j, i] = s\n",
    "    np.fill_diagonal(S, 1.0)\n",
    "    return S\n",
    "\n",
    "print(\"Construindo S_cf (min_overlap=1) ...\")\n",
    "S_cf = build_S_cf(n_items, item_ratings, min_overlap=1)\n",
    "\n",
    "print(\"Construindo S_content (Jaccard gêneros) ...\")\n",
    "S_content = build_S_content(n_items, genres_by_item)\n",
    "\n",
    "L1 = 5  # limiar de usuários em comum\n",
    "print(f\"Construindo S_hybrid (L1={L1}) ...\")\n",
    "S_hybrid = build_S_hybrid(n_items, item_ratings, genres_by_item, L1=L1)\n",
    "\n",
    "# ---------- Predição item-based KNN ----------\n",
    "def knn_predict(uid, iid, S, k=10):\n",
    "    uid, iid = int(uid), int(iid)\n",
    "    hist = user_ratings.get(uid, {})\n",
    "    if not hist or iid >= S.shape[0]:\n",
    "        return 3.0\n",
    "    sims = []\n",
    "    for j, r in hist.items():\n",
    "        if j < S.shape[1]:\n",
    "            s = float(S[iid, j])\n",
    "            if s > 0:\n",
    "                sims.append((s, r))\n",
    "    sims.sort(key=lambda x: x[0], reverse=True)\n",
    "    sims = sims[:k]\n",
    "    if not sims:\n",
    "        # fallback: média do usuário\n",
    "        return float(np.mean(list(hist.values())))\n",
    "    num = sum(s*r for s, r in sims)\n",
    "    den = sum(s for s, _ in sims)\n",
    "    return (num / den) if den != 0 else float(np.mean(list(hist.values())))\n",
    "\n",
    "def evaluate_on(S, k=10):\n",
    "    preds = [knn_predict(u, i, S, k=k) for u, i in zip(test.userId, test.movieId)]\n",
    "    return mae_rmse(test.rating, preds)\n",
    "\n",
    "# ---------- Avaliar e comparar ----------\n",
    "for k in [5, 10, 20]:\n",
    "    mae_cf, rmse_cf = evaluate_on(S_cf, k=k)\n",
    "    mae_ct, rmse_ct = evaluate_on(S_content, k=k)\n",
    "    mae_hy, rmse_hy = evaluate_on(S_hybrid, k=k)\n",
    "    print(f\"\\nK={k}\")\n",
    "    print(f\"  CF (cosseno)     -> MAE={mae_cf:.4f}  RMSE={rmse_cf:.4f}\")\n",
    "    print(f\"  Conteúdo (gênero)-> MAE={mae_ct:.4f}  RMSE={rmse_ct:.4f}\")\n",
    "    print(f\"  Híbrido (L1={L1}) -> MAE={mae_hy:.4f}  RMSE={rmse_hy:.4f}\")\n",
    "\n",
    "print(\"\\nInterpretação rápida:\")\n",
    "print(\"- Com L1 maior, a matriz híbrida privilegia CF quando há bastante sobreposição;\")\n",
    "print(\"  para pares raros, recorre a conteúdo, cobrindo sparsidade. Em geral melhora RMSE.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ae3aa0",
   "metadata": {},
   "source": [
    "***Exercício 02:*** Vamos implementar um recomendador híbrido canalizado em cascata, no cenário de ranqueamento. A ideia é que um primeiro algoritmo gere uma lista C1 de N=50 itens candidatos à recomendação para cada usuário. Em seguida, um outro recomendador irá gerar uma outra lista C2 também de N=50 itens candidatos à rcomendação para cada usuário. Por fim, o ranking final será a intersecção entre C1 e C2, sendo o score de cada itens formado pela média aritmética dos scores de cada lista. Avalie o desempenho.\n",
    "\n",
    "Dica 1: utilize o parâmetro rank_length disponível nos algoritmos de ranqueamento do CaseRecommender para especificar o tamanho N de recomendações para cada usuário.\n",
    "\n",
    "Dica 2: você pode gravar num arquivo os rankings gerados por um algoritmo para cada usuário especificando o nome do arquivo no parâmetro output_file.\n",
    "\n",
    "Dica 3: consulte a Aula 04 que contém algumas métricas de avaliação de ranqueamento. Como você irá gerar o ranking final externamente ao CaseRecommender, será necessário avaliá-lo usando funções próprias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a682b8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avaliação @K=10 (usuários avaliados: 11090)\n",
      "Stage 1 (CF):         {'P@K': 0.0001, 'R@K': 0.0001, 'nDCG@K': 0.0002, 'MAP@K': 0.0002}\n",
      "Stage 2 (Conteúdo):   {'P@K': 0.0106, 'R@K': 0.0364, 'nDCG@K': 0.0551, 'MAP@K': 0.0416}\n",
      "Cascata (Interseção): {'P@K': 0.0001, 'R@K': 0.0001, 'nDCG@K': 0.0002, 'MAP@K': 0.0001}\n",
      "\n",
      "Notas:\n",
      "- A cascata tende a aumentar a precisão/diversidade ao exigir concordância entre os modelos.\n",
      "- Se a interseção for pequena, o fallback usa o Stage 1. Você pode trocar por união com penalidade.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Reusa S_cf e S_content do Ex. 01 (se não existirem, crie-os antes)\n",
    "\n",
    "# ---------- Scoring por usuário ----------\n",
    "def score_items_for_user(uid, S, candidate_items):\n",
    "    uid = int(uid)\n",
    "    hist = user_ratings.get(uid, {})\n",
    "    if not hist:\n",
    "        return {i: 0.0 for i in candidate_items}\n",
    "    scores = {}\n",
    "    for iid in candidate_items:\n",
    "        s_list = []\n",
    "        for j, r in hist.items():\n",
    "            if iid < S.shape[0] and j < S.shape[1]:\n",
    "                s = float(S[iid, j])\n",
    "                if s > 0:\n",
    "                    s_list.append((s, r))\n",
    "        if s_list:\n",
    "            num = sum(s*r for s, r in s_list)\n",
    "            den = sum(s for s, _ in s_list)\n",
    "            scores[iid] = (num/den) if den != 0 else np.mean(list(hist.values()))\n",
    "        else:\n",
    "            scores[iid] = np.mean(list(hist.values()))\n",
    "    return scores\n",
    "\n",
    "def unseen_items(uid, n_items):\n",
    "    seen = set(user_ratings.get(int(uid), {}).keys())\n",
    "    return [i for i in range(n_items) if i not in seen]\n",
    "\n",
    "def topN_from_scores(scores_dict, N):\n",
    "    # retorna lista ordenada de (item, score)\n",
    "    items_scores = sorted(scores_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    return items_scores[:N]\n",
    "\n",
    "# ---------- Métricas de ranking ----------\n",
    "def eval_ranking(users, rankings, test_df, K=10, rel_threshold=3.0):\n",
    "    # rankings: dict {u: [item1,item2,...]}\n",
    "    # ground truth: relevantes no test (rating >= threshold)\n",
    "    test_rel = defaultdict(set)\n",
    "    for u, i, r in test_df[['userId','movieId','rating']].itertuples(index=False):\n",
    "        if r >= rel_threshold:\n",
    "            test_rel[int(u)].add(int(i))\n",
    "\n",
    "    precisions, recalls, ndcgs, aps = [], [], [], []\n",
    "\n",
    "    def dcg(rels):\n",
    "        return sum((rel / np.log2(idx+2)) for idx, rel in enumerate(rels))\n",
    "\n",
    "    for u in users:\n",
    "        rec_list = rankings.get(u, [])[:K]\n",
    "        if not rec_list:\n",
    "            continue\n",
    "        relset = test_rel.get(u, set())\n",
    "        hits = [1.0 if i in relset else 0.0 for i in rec_list]\n",
    "\n",
    "        # Precision@K / Recall@K\n",
    "        P = sum(hits) / len(rec_list)\n",
    "        R = (sum(hits) / len(relset)) if relset else 0.0\n",
    "\n",
    "        # nDCG@K\n",
    "        dcg_val = dcg(hits)\n",
    "        ideal_hits = sorted(hits, reverse=True)\n",
    "        idcg_val = dcg(ideal_hits) if ideal_hits else 1.0\n",
    "        nDCG = dcg_val / idcg_val if idcg_val > 0 else 0.0\n",
    "\n",
    "        # AP@K\n",
    "        cum, ap_sum = 0.0, 0.0\n",
    "        for idx, h in enumerate(hits, 1):\n",
    "            if h > 0:\n",
    "                cum += 1\n",
    "                ap_sum += cum / idx\n",
    "        AP = (ap_sum / sum(hits)) if sum(hits) > 0 else 0.0\n",
    "\n",
    "        precisions.append(P); recalls.append(R); ndcgs.append(nDCG); aps.append(AP)\n",
    "\n",
    "    def avg(x): return float(np.mean(x)) if x else 0.0\n",
    "    return {\n",
    "        \"P@K\": avg(precisions),\n",
    "        \"R@K\": avg(recalls),\n",
    "        \"nDCG@K\": avg(ndcgs),\n",
    "        \"MAP@K\": avg(aps),\n",
    "        \"Users@K\": len(precisions)\n",
    "    }\n",
    "\n",
    "# ---------- Pipeline em Cascata ----------\n",
    "N = 50      # tamanho da lista de candidatos de cada estágio\n",
    "K = 10      # corte para avaliação final\n",
    "users = sorted(user_ratings.keys())\n",
    "n_items_total = int(df.movieId.max()) + 1\n",
    "\n",
    "rank_stage1 = {}   # CF\n",
    "rank_stage2 = {}   # Conteúdo\n",
    "rank_cascade = {}  # Interseção + média\n",
    "\n",
    "for u in users:\n",
    "    cands = unseen_items(u, n_items_total)\n",
    "\n",
    "    # Stage 1 (CF)\n",
    "    scores1 = score_items_for_user(u, S_cf, cands)\n",
    "    top1 = topN_from_scores(scores1, N)\n",
    "    rank_stage1[u] = [i for i, _ in top1]\n",
    "\n",
    "    # Stage 2 (Conteúdo)\n",
    "    scores2 = score_items_for_user(u, S_content, cands)\n",
    "    top2 = topN_from_scores(scores2, N)\n",
    "    rank_stage2[u] = [i for i, _ in top2]\n",
    "\n",
    "    # Cascata: interseção + média (normalizada por usuário para equilíbrio)\n",
    "    set1, set2 = set(rank_stage1[u]), set(rank_stage2[u])\n",
    "    inter = list(set1 & set2)\n",
    "\n",
    "    if inter:\n",
    "        # normalização min-max por usuário em cada estágio\n",
    "        def normalize(scores, items):\n",
    "            vals = np.array([scores[i] for i in items], float)\n",
    "            vmin, vmax = vals.min(), vals.max()\n",
    "            return {i: (scores[i]-vmin)/(vmax-vmin+1e-12) for i in items}\n",
    "\n",
    "        norm1 = normalize(scores1, inter)\n",
    "        norm2 = normalize(scores2, inter)\n",
    "        fused = {i: 0.5*norm1[i] + 0.5*norm2[i] for i in inter}\n",
    "        rank_cascade[u] = [i for i, _ in sorted(fused.items(), key=lambda x: x[1], reverse=True)[:K]]\n",
    "    else:\n",
    "        # fallback: usa Stage 1\n",
    "        rank_cascade[u] = rank_stage1[u][:K]\n",
    "\n",
    "# ---------- Avaliação (comparar 3 listas) ----------\n",
    "res1 = eval_ranking(users, rank_stage1, test, K=K)\n",
    "res2 = eval_ranking(users, rank_stage2, test, K=K)\n",
    "resc = eval_ranking(users, rank_cascade, test, K=K)\n",
    "\n",
    "print(f\"\\nAvaliação @K={K} (usuários avaliados: {resc['Users@K']})\")\n",
    "print(\"Stage 1 (CF):        \", {k: round(v,4) for k,v in res1.items() if k!='Users@K'})\n",
    "print(\"Stage 2 (Conteúdo):  \", {k: round(v,4) for k,v in res2.items() if k!='Users@K'})\n",
    "print(\"Cascata (Interseção):\", {k: round(v,4) for k,v in resc.items() if k!='Users@K'})\n",
    "\n",
    "print(\"\\nNotas:\")\n",
    "print(\"- A cascata tende a aumentar a precisão/diversidade ao exigir concordância entre os modelos.\")\n",
    "print(\"- Se a interseção for pequena, o fallback usa o Stage 1. Você pode trocar por união com penalidade.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
